tokens_tolower() |>
tokens_remove(stopwords('en')) |>
tokens_wordstem() |>
dfm()
dtm <- dfm_trim(dtm, min_termfreq = 10)
dtm
textplot_wordcloud(dfm_subset(dtm, rank == "good"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, rank == "good"), n =10)
confusionMatrix(tab_class, mode = "everything", positive = "pos")
library(caret)
confusionMatrix(tab_class, mode = "everything", positive = "pos")
confusionMatrix(tab_class, mode = "everything", positive = "pos")
confusionMatrix(tab_class, mode = "everything", positive = "pos")
confusionMatrix(tab_class, mode = "everything", positive = "pos")
confusionMatrix(tab_class, mode = "everything", positive = "pos")
textplot_wordcloud(dfm_subset(dtm, rank == "bad"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, rank == "bad"), n =10)
library(quanteda.textmodels)
library(quanteda.textstats)
textplot_wordcloud(dfm_subset(dtm, rank == "bad"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, rank == "bad"), n =10)
ggp <- ggplot(tstat_freq, aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$rank
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
tab_class
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$rank
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
tab_class
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$rank
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
tab_class
tmod_nb <- textmodel_nb(dfmat_training, docvars(dfmat_training)$rank)
summary(tmod_nb)
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$rank
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
tab_class
confusionMatrix(tab_class, mode = "everything", positive = "pos")
confusionMatrix
tmod1 <- textmodel_lr(dfmat_training, docvars(dfmat_training)$rank)
summary(tmod1)
coef(tmod1)
predicted_class <- predict(tmod1, newdata = dfmat_test)
predicted_class <- predict(tmod1, newdata = dfmat_matched)
predicted_class <- predict(tmod1, newdata = dfmat_matched)
predicted_class <- predict(tmod1)
tmod1 <- textmodel_lr(dfmat_training, docvars(dfmat_training)$rank)
summary(tmod1)
coef(tmod1)
predicted_class <- predict(tmod1,newdata = dfmat_matched)
predicted_class <- predict(tmod1,newdata = dfmat_matched)
predicted_class <- predict(tmod1,newdata = dfmat_matched)
predicted_class <- predict(tmod1,newdata = dfmat_matched)
tmod_nb <- textmodel_lr(dfmat_training, docvars(dfmat_training)$rank)
summary(tmod_nb)
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$rank
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
auc<-roc(as.factor(spam.test[,1])
tmod1 <- textmodel_lr(dfmat_training, docvars(dfmat_training)$rank)
auc<-roc(as.factor(spam.test[,1]))
x <- evalm(predicted_class)
x <- evalm(predicted_class)
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textmodels)
library(quanteda.textstats)
library(dplyr)
library(textplot)
library(ggplot2)
library(ggpubr)
library(caret)
reviews <- read.csv("~/Amazon/reviews_Video_Games.csv", sep=";")
reviews <- reviews %>% select(reviewText, overall,summary)
reviews$ID <- 1:nrow(reviews)
summary(reviews)
reviews <- subset(reviews, overall != 3)
reviews <- reviews %>% mutate(sentiment =
case_when(overall <= 2 ~ "bad",
overall >= 4 ~ "good")
)
sentimentable <- table(reviews$sentiment)
labels <- paste(names(sentimentable), "\n", sentimentable, sep="")
pie(sentimentable, labels = labels,
main="Pie Chart of sentimentn distribution")
goodsample <- reviews[ sample(which ( reviews$sentiment == "good" ) ,28000), ]
badsample <- reviews[ sample(which ( reviews$sentiment == "bad" ) ,28000), ]
reviews <- rbind(goodsample,badsample)
corp <- corpus(reviews, text_field = 'reviewText')
## create the corpus
corp
custom_english <- stopwords("english")[! stopwords("english") %in% c("isn't", "aren't",     "wasn't" ,    "weren't"  ,  "hasn't"  ,   "haven't"  ,  "hadn't"  ,   "doesn't",    "don't" ,     "didn't","won't","wouldn't","shan't","shouldn't","can't","cannot","couldn't",   "mustn't","no","nor","not")]
custom_english <-
dtm <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_symbols = T) |>
tokens_tolower() |>
tokens_remove(custom_english) |>
tokens_wordstem() |>
dfm()
dtm <- dfm_trim(dtm, min_termfreq = 10)
dtm
par(mfrow=c(1,2)) # for 1 row, 2 cols
textplot_wordcloud(dfm_subset(dtm, sentiment == "good"),min_size = 1,
max_size = 5, max_words = 100, rotation = 0.1)
textplot_wordcloud(dfm_subset(dtm, sentiment == "bad"),min_size = 1,
max_size = 5, max_words = 100, rotation = 0.1)
ggp1 <- ggplot(textstat_frequency(dfm_subset(dtm, sentiment == "good"), n =10), aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency")+
theme_minimal()
ggp2 <- ggplot(textstat_frequency(dfm_subset(dtm, sentiment == "bad"), n =10), aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp <- ggarrange(ggp1, ggp2,
labels = c("Good reviews", "Bad reviews"),
font.label = list(size = 8, face = "bold", color = "red"),
hjust = -2,
ncol = 2, nrow = 1)
ggp
set.seed(300)
id_train <- createDataPartition(docvars(dtm)$sentiment, p = .8,
list = FALSE,
times = 1)
# get training set
dfmat_training <- dfm_subset(dtm, !docvars(dtm)$ID %in% id_train)
# get test set (documents not in id_train)
dfmat_test <- dfm_subset(dtm, docvars(dtm)$ID %in% id_train)
tmod_nb <- textmodel_nb(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod_nb)
#This model requires that the features from the training dataset be the same of those in the testing, so we match the features of the two partitions before testing
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
tab_class
confusionMatrix(tab_class, mode = "everything",positive = "good")
confusionMatrix
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textmodels)
library(quanteda.textstats)
library(dplyr)
library(textplot)
library(ggplot2)
library(caret)
reviews <- read.csv("~/Amazon/reviews_Video_Games.csv", sep=";")
reviews <- reviews %>% select(reviewText, overall,summary)
reviews$ID <- 1:nrow(reviews)
summary(reviews)
reviews <- subset(reviews, overall != 3)
reviews <- reviews %>% mutate(sentiment =
case_when(overall <= 2 ~ "bad",
overall >= 4 ~ "good")
)
sentimentable <- table(reviews$sentiment)
labels <- paste(names(sentimentable), "\n", sentimentable, sep="")
pie(sentimentable, labels = labels,
main="Pie Chart of sentimenting distribution")
goodsample <- reviews[ sample(which ( reviews$sentiment == "good" ) ,20000), ]
badsample <- reviews[ sample(which ( reviews$sentiment == "bad" ) ,20000), ]
reviews <- rbind(goodsample,badsample)
sentimentable <- table(reviews$sentiment)
labels <- paste(names(sentimentable), "\n", sentimentable, sep="")
pie(sentimentable, labels = labels,
main="Pie Chart of sentimenting distribution")
custom_english <- stopwords("english")[! stopwords("english") %in% c("isn't",      "aren't",     "wasn't" ,    "weren't"  ,  "hasn't"  ,   "haven't"  ,  "hadn't"  ,   "doesn't",    "don't" ,     "didn't","won't","wouldn't","shan't","shouldn't","can't","cannot","couldn't",   "mustn't","no","nor","not")]
corp <- corpus(reviews, text_field = 'reviewText')
dtm1 <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_symbols = T) |>
tokens_tolower() |>
tokens_remove(custom_english) |>
tokens_wordstem() |>
dfm()
textplot_wordcloud(dfm_subset(dtm, sentiment == "good"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, sentiment == "good"), n =10)
ggp <- ggplot(tstat_freq, aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp
textplot_wordcloud(dfm_subset(dtm, sentiment == "bad"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, sentiment == "bad"), n =10)
ggp <- ggplot(tstat_freq, aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp
#set.seed(300)
#id_train <- sample(1:60000, 50000, replace = FALSE)
set.seed(300)
id_train <- createDataPartition(docvars(dtm1)$sentiment, p = .8,
list = FALSE,
times = 1)
# get training set
dfmat_test <- dfm_subset(dtm1, !docvars(dtm1)$ID %in% id_train)
# get test set (documents not in id_train)
dfmat_training <- dfm_subset(dtm1, docvars(dtm1)$ID %in% id_train)
tmod_nb <- textmodel_nb(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod_nb)
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
tab_class
confusionMatrix(tab_class, mode = "everything")
confusionMatrix
tmod1 <- textmodel_lr(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod1)
tmod_nb <- textmodel_lr(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod_nb)
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textmodels)
library(quanteda.textstats)
library(dplyr)
library(textplot)
library(ggplot2)
library(caret)
reviews <- read.csv("~/Amazon/reviews_Video_Games.csv", sep=";")
reviews <- reviews %>% select(reviewText, overall,summary)
reviews$ID <- 1:nrow(reviews)
summary(reviews)
reviews <- subset(reviews, overall != 3)
reviews <- reviews %>% mutate(sentiment =
case_when(overall <= 2 ~ "bad",
overall >= 4 ~ "good")
)
sentimentable <- table(reviews$sentiment)
labels <- paste(names(sentimentable), "\n", sentimentable, sep="")
pie(sentimentable, labels = labels,
main="Pie Chart of sentimenting distribution")
goodsample <- reviews[ sample(which ( reviews$sentiment == "good" ) ,20000), ]
badsample <- reviews[ sample(which ( reviews$sentiment == "bad" ) ,20000), ]
reviews <- rbind(goodsample,badsample)
sentimentable <- table(reviews$sentiment)
labels <- paste(names(sentimentable), "\n", sentimentable, sep="")
pie(sentimentable, labels = labels,
main="Pie Chart of sentimenting distribution")
custom_english <- stopwords("english")[! stopwords("english") %in% c("isn't",      "aren't",     "wasn't" ,    "weren't"  ,  "hasn't"  ,   "haven't"  ,  "hadn't"  ,   "doesn't",    "don't" ,     "didn't","won't","wouldn't","shan't","shouldn't","can't","cannot","couldn't",   "mustn't","no","nor","not")]
corp <- corpus(reviews, text_field = 'reviewText')
dtm1 <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_symbols = T) |>
tokens_tolower() |>
tokens_remove(custom_english) |>
tokens_wordstem() |>
dfm()
textplot_wordcloud(dfm_subset(dtm, sentiment == "good"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, sentiment == "good"), n =10)
ggp <- ggplot(tstat_freq, aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp
textplot_wordcloud(dfm_subset(dtm, sentiment == "bad"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, sentiment == "bad"), n =10)
ggp <- ggplot(tstat_freq, aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp
#set.seed(300)
#id_train <- sample(1:60000, 50000, replace = FALSE)
set.seed(300)
id_train <- createDataPartition(docvars(dtm1)$sentiment, p = 1,
list = FALSE,
times = 1)
# get training set
dfmat_test <- dfm_subset(dtm1, !docvars(dtm1)$ID %in% id_train)
# get test set (documents not in id_train)
dfmat_training <- dfm_subset(dtm1, docvars(dtm1)$ID %in% id_train)
tmod_nb <- textmodel_nb(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod_nb)
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
tab_class
confusionMatrix(tab_class, mode = "everything")
confusionMatrix
tmod1 <- textmodel_lr(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod1)
tmod_nb <- textmodel_lr(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod_nb)
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
set.seed(300)
id_train <- createDataPartition(docvars(dtm1)$sentiment, p = .8,
list = FALSE,
times = 1)
# get training set
dfmat_test <- dfm_subset(dtm1, !docvars(dtm1)$ID %in% id_train)
# get test set (documents not in id_train)
dfmat_training <- dfm_subset(dtm1, docvars(dtm1)$ID %in% id_train)
tmod_nb <- textmodel_nb(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod_nb)
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
confusionMatrix(tab_class, mode = "everything")
confusionMatrix
set.seed(300)
id_train <- createDataPartition(docvars(dtm1)$sentiment, p = .8,
list = FALSE,
times = 1)
# get training set
dfmat_test <- dfm_subset(dtm1, docvars(dtm1)$ID %in% id_train)
# get test set (documents not in id_train)
dfmat_training <- dfm_subset(dtm1, !docvars(dtm1)$ID %in% id_train)
tmod_nb <- textmodel_nb(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod_nb)
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
confusionMatrix(tab_class, mode = "everything")
confusionMatrix
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
confusionMatrix(tab_class, mode = "everything",positive = 'good')
confusionMatrix
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
confusionMatrix(tab_class, mode = "everything",positive = 'gooed')
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
confusionMatrix(tab_class, mode = "everything",positive = 'good')
confusionMatrix
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
confusionMatrix(tab_class, mode = "everything",positive = 'good')
confusionMatrix
textplot_wordcloud(dfm_subset(dtm, sentiment == "good"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, sentiment == "good"), n =10)
ggp <- ggplot(tstat_freq, aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textmodels)
library(quanteda.textstats)
library(dplyr)
library(textplot)
library(ggplot2)
library(caret)
reviews <- read.csv("~/Amazon/reviews_Video_Games.csv", sep=";")
reviews <- reviews %>% select(reviewText, overall,summary)
reviews$ID <- 1:nrow(reviews)
summary(reviews)
reviews <- subset(reviews, overall != 3)
reviews <- reviews %>% mutate(sentiment =
case_when(overall <= 2 ~ "bad",
overall >= 4 ~ "good")
)
sentimentable <- table(reviews$sentiment)
labels <- paste(names(sentimentable), "\n", sentimentable, sep="")
pie(sentimentable, labels = labels,
main="Pie Chart of sentimenting distribution")
goodsample <- reviews[ sample(which ( reviews$sentiment == "good" ) ,20000), ]
badsample <- reviews[ sample(which ( reviews$sentiment == "bad" ) ,20000), ]
reviews <- rbind(goodsample,badsample)
sentimentable <- table(reviews$sentiment)
labels <- paste(names(sentimentable), "\n", sentimentable, sep="")
pie(sentimentable, labels = labels,
main="Pie Chart of sentimenting distribution")
custom_english <- stopwords("english")[! stopwords("english") %in% c("isn't",      "aren't",     "wasn't" ,    "weren't"  ,  "hasn't"  ,   "haven't"  ,  "hadn't"  ,   "doesn't",    "don't" ,     "didn't","won't","wouldn't","shan't","shouldn't","can't","cannot","couldn't",   "mustn't","no","nor","not")]
corp <- corpus(reviews, text_field = 'reviewText')
dtm1 <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_symbols = T) |>
tokens_tolower() |>
tokens_remove(custom_english) |>
tokens_wordstem() |>
dfm()
textplot_wordcloud(dfm_subset(dtm, sentiment == "good"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, sentiment == "good"), n =10)
ggp <- ggplot(tstat_freq, aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp
textplot_wordcloud(dfm_subset(dtm, sentiment == "bad"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, sentiment == "bad"), n =10)
ggp <- ggplot(tstat_freq, aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp
set.seed(300)
id_train <- createDataPartition(docvars(dtm1)$sentiment, p = .8,
list = FALSE,
times = 1)
# get training set
dfmat_test <- dfm_subset(dtm1, docvars(dtm1)$ID %in% id_train)
# get test set (documents not in id_train)
dfmat_training <- dfm_subset(dtm1, !docvars(dtm1)$ID %in% id_train)
tmod_nb <- textmodel_nb(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod_nb)
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
confusionMatrix(tab_class, mode = "everything",positive = 'good')
confusionMatrix
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textmodels)
library(quanteda.textstats)
library(dplyr)
library(textplot)
library(ggplot2)
library(caret)
reviews <- read.csv("~/Amazon/reviews_Video_Games.csv", sep=";")
reviews <- reviews %>% select(reviewText, overall,summary)
reviews$ID <- 1:nrow(reviews)
summary(reviews)
reviews <- subset(reviews, overall != 3)
reviews <- reviews %>% mutate(sentiment =
case_when(overall <= 2 ~ "bad",
overall >= 4 ~ "good")
)
sentimentable <- table(reviews$sentiment)
labels <- paste(names(sentimentable), "\n", sentimentable, sep="")
pie(sentimentable, labels = labels,
main="Pie Chart of sentimenting distribution")
goodsample <- reviews[ sample(which ( reviews$sentiment == "good" ) ,20000), ]
badsample <- reviews[ sample(which ( reviews$sentiment == "bad" ) ,20000), ]
reviews <- rbind(goodsample,badsample)
sentimentable <- table(reviews$sentiment)
labels <- paste(names(sentimentable), "\n", sentimentable, sep="")
pie(sentimentable, labels = labels,
main="Pie Chart of sentimenting distribution")
custom_english <- stopwords("english")[! stopwords("english") %in% c("isn't",      "aren't",     "wasn't" ,    "weren't"  ,  "hasn't"  ,   "haven't"  ,  "hadn't"  ,   "doesn't",    "don't" ,     "didn't","won't","wouldn't","shan't","shouldn't","can't","cannot","couldn't",   "mustn't","no","nor","not")]
corp <- corpus(reviews, text_field = 'reviewText')
dtm <- corp |>
tokens(remove_punct = T, remove_numbers = T, remove_symbols = T) |>
tokens_tolower() |>
tokens_remove(custom_english) |>
tokens_wordstem() |>
dfm()
textplot_wordcloud(dfm_subset(dtm, sentiment == "good"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, sentiment == "good"), n =10)
ggp <- ggplot(tstat_freq, aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp
textplot_wordcloud(dfm_subset(dtm, sentiment == "bad"))
tstat_freq <- textstat_frequency(dfm_subset(dtm, sentiment == "bad"), n =10)
ggp <- ggplot(tstat_freq, aes(reorder(feature,frequency), frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggp
set.seed(300)
id_train <- createDataPartition(docvars(dtm1)$sentiment, p = .8,
list = FALSE,
times = 1)
# get training set
dfmat_test <- dfm_subset(dtm1, docvars(dtm1)$ID %in% id_train)
# get test set (documents not in id_train)
dfmat_training <- dfm_subset(dtm1, !docvars(dtm1)$ID %in% id_train)
tmod_nb <- textmodel_nb(dfmat_training, docvars(dfmat_training)$sentiment)
summary(tmod_nb)
dfmat_matched <- dfm_match(dfmat_test, features = featnames(dfmat_training))
actual_class <- docvars(dfmat_matched)$sentiment
predicted_class <- predict(tmod_nb, newdata = dfmat_matched)
tab_class <- table(actual_class, predicted_class)
confusionMatrix(tab_class, mode = "everything",positive = 'good')
confusionMatrix
